{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17166a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to kill all processes\n",
    "# sudo kill -9 $(pgrep -f python3)\n",
    "# sudo kill -9 $(pgrep -f conformanceTests)\n",
    "\n",
    "# import subprocess\n",
    "# subprocess.run([\"kill\" \"-9\" $(pgrep -f conformanceTests)\"])\n",
    "import os\n",
    "os.system(\"kill -9 $(pgrep -f conformanceTests)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlsxwriter==3.0.2\n",
    "!pip install beautifulsoup4==4.10.0\n",
    "!pip install utils==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "python_exec = '/home/nsemaev/code/venv/bin/python3.8'\n",
    "\n",
    "work_path = os.getcwd()\n",
    "\n",
    "binary_type = 'master_2022_02_15'\n",
    "binary_name = f\"conformanceTests_{binary_type}\"\n",
    "binary_path = f\"{work_path}/bin/{binary_name}\"\n",
    "\n",
    "\n",
    "ci_report_file = f\"{work_path}/ci_reports/\" + \"2022_02_15.html\"\n",
    "report_plugin_position = 4\n",
    "\n",
    "results_path = f\"{work_path}/{binary_type}\"\n",
    "\n",
    "ping_time = 60 * 5\n",
    "\n",
    "cores = 16\n",
    "\n",
    "irs_path = '/home/nsemaev/Documents/ops/'\n",
    "\n",
    "skipped_ops = ['boolean', 'ROIAlign']\n",
    "time_wasting_ops = ['BinaryConvolution', 'Convolution', 'ConvolutionBackpropData', 'DeformableConvolution', \n",
    "                    'GroupConvolution', 'GroupConvolutionBackpropData', 'MaxPool', 'AvgPool', 'Interpolate',\n",
    "                    'TensorIterator', 'MVN', 'Reshape']\n",
    "\n",
    "all_ops = sorted(os.listdir(irs_path))\n",
    "\n",
    "run_results = ['passed', 'failed', 'skipped', 'crashed', 'empty']\n",
    "ci_results = ['passed', 'failed', 'skipped', 'crashed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_irs_list(operation):\n",
    "    precision_irs_dict = [{} for i in range(10)]\n",
    "    for precision in os.listdir(f\"{irs_path}/{operation}\"):\n",
    "        assert os.path.isdir(f\"{irs_path}/{operation}/{precision}\")\n",
    "        for file_name in os.listdir(f\"{irs_path}/{operation}/{precision}\"):\n",
    "            _, file_extension = os.path.splitext(file_name)\n",
    "            if file_extension == '.xml':\n",
    "                ir_id = int(re.findall(fr\"{operation}_(\\d+)\\.xml\", file_name)[0])\n",
    "                with open(f\"{irs_path}/{operation}/{precision}/{file_name}\") as xml_file:\n",
    "                    xml_data = str(xml_file.read())\n",
    "                opset = int(re.findall(fr'type=\"{operation.lower()}\" version=\"opset(\\d+)\">', xml_data.lower())[0])\n",
    "                if precision not in precision_irs_dict[opset]:\n",
    "                    precision_irs_dict[opset][precision] = []\n",
    "#                 print(opset, type(opset))\n",
    "                precision_irs_dict[opset][precision].append(ir_id)\n",
    "    return precision_irs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_precision_irs_list('Add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import subprocess\n",
    "import _thread\n",
    "import threading\n",
    "from contextlib import contextmanager\n",
    "import re\n",
    "import xlsxwriter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "completed_ops = []\n",
    "if os.path.exists(results_path):\n",
    "    completed_ops = [op.split('_')[0] for op in os.listdir(results_path) if op.split('_')[-1] == 'completed']\n",
    "logs_files = {}\n",
    "\n",
    "class GTestParallel():\n",
    "    def __init__(self, operation: str):\n",
    "        print(f\"\\n\\n\\n{operation}\")\n",
    "        self.operation = operation\n",
    "        self.op_results_path = f\"{results_path}/{self.operation}_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
    "        self.precision_irs_list = get_precision_irs_list(self.operation)\n",
    "#         self.reports_path = f\"{self.op_results_path}_reports\"\n",
    "#         os.makedirs(self.reports_path)\n",
    "        for opset in range(len(self.precision_irs_list)):\n",
    "            for precision in self.precision_irs_list[opset]:\n",
    "                for ir_id in self.precision_irs_list[opset][precision]:\n",
    "                    dst_folder = f\"{self.operation}_opset{opset}_{precision}_{ir_id}\"\n",
    "                    dst_path = f\"{self.op_results_path}/{dst_folder}/ir\"\n",
    "                    os.makedirs(dst_path)\n",
    "                    for extension in ['xml', 'bin', 'meta']:\n",
    "                        ir_file_name = f\"{self.operation}_{ir_id}.{extension}\"\n",
    "                        src_path = f\"{irs_path}/{self.operation}/{precision}\"\n",
    "                        shutil.copyfile(f\"{src_path}/{ir_file_name}\", f\"{dst_path}/{ir_file_name}\")\n",
    "               \n",
    "    def get_command(self, folder: str):\n",
    "        return f\"{python_exec} {work_path}/gtest_parallel.py {binary_path} -d . \" + \\\n",
    "            f\"--gtest_filter=*ReadIRTest*{self.operation}* \" + \\\n",
    "            f\"-- \" + \\\n",
    "            f\"--input_folders={self.op_results_path}/{folder}/ir \" + \\\n",
    "            f\"--device=TEMPLATE \" + \\\n",
    "            f\"--output_folder={self.op_results_path}/{folder}\"\n",
    "#             f\"--report_unique_name \" + \\\n",
    "#             f\"--output_folder={self.op_results_path}/{folder}/gtest-parallel-xmls\"\n",
    "    \n",
    "    def run (self, time_limit):\n",
    "        completed = 0\n",
    "        start_time = time.time()\n",
    "        waiting_time = 10\n",
    "        for folder in os.listdir(self.op_results_path):\n",
    "            command = self.get_command(folder)\n",
    "            threading.Thread(target=os.system, args=(f\"cd {self.op_results_path}/{folder} && {command}\",)).start()\n",
    "        while completed < len(os.listdir(self.op_results_path)):\n",
    "            for folder in os.listdir(self.op_results_path):\n",
    "                if not folder.endswith('completed'):\n",
    "                    if os.path.exists(f\"{self.op_results_path}/{folder}/gtest-parallel-logs/passed\") or \\\n",
    "                       os.path.exists(f\"{self.op_results_path}/{folder}/gtest-parallel-logs/failed\"):\n",
    "#                         report_name = f\"{folder}_report.xml\"\n",
    "#                         if os.path.exists(f\"{self.op_results_path}/{folder}/report.xml\"):\n",
    "#                             os.rename(f\"{self.op_results_path}/{folder}/report.xml\", \n",
    "#                                       f\"{self.op_results_path}/{folder}/{report_name}\")\n",
    "#                             shutil.copyfile(f\"{self.op_results_path}/{folder}/{report_name}\", \n",
    "#                                             f\"{self.reports_path}/{report_name}\")\n",
    "                        os.rename(f\"{self.op_results_path}/{folder}\", \n",
    "                                  f\"{self.op_results_path}/{folder}_{int(time.time() - start_time)}s_completed\")\n",
    "                        completed += 1\n",
    "            if datetime.now().strftime('%Y_%m_%d %H:%M:%S')[-1] == '0':\n",
    "                print(f\"{datetime.now().strftime('%Y_%m_%d %H:%M:%S')} {self.operation} ({time.time() - start_time} of {time_limit})\")\n",
    "                print(f\"{completed} of {len(os.listdir(self.op_results_path))}\")\n",
    "            if time.time() - start_time > time_limit:\n",
    "                os.system('kill -9 $(pgrep -f conformanceTests)')\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        os.rename(f\"{self.op_results_path}\", \n",
    "                  f\"{self.op_results_path}_{completed}_of_{len(os.listdir(self.op_results_path))}_{int(time.time() - start_time)}s_completed\")\n",
    "    \n",
    "    def get_precision_irs_dict(self):\n",
    "        for precision in os.listdir(f\"{irs_path}/{self.op}/\"):\n",
    "            assert os.path.isdir(f\"{irs_path}/{self.op}/{precision}/\")\n",
    "            for file_name in os.listsir(f\"{irs_path}/{self.op}/{precision}/\"):\n",
    "                _, file_extension = os.path.splitext(file_name)\n",
    "        \n",
    "    def generate_tmp_irs_path(self, irs_path: str, ir_id: int):\n",
    "        os.makedirs(f\"{work_path}/tmp/{self.op}_{ir_id}\")\n",
    "        shutil.copyfile(f\"{irs_path}/\", dst)\n",
    "        \n",
    "    \n",
    "\n",
    "#     def run_while_not_end(self, op_time=30, time_limited=True):\n",
    "#         process_start_time = time.time()\n",
    "#         current_time = datetime.now().strftime('%Y_%m_%d %H:%M:%S')\n",
    "#         print(f\"{current_time} {self.op} was started\")\n",
    "#         print(self.command)\n",
    "#         if os.path.exists(self.op_path):\n",
    "#             shutil.rmtree(self.op_path)\n",
    "#         os.makedirs(self.op_path)\n",
    "#         os.chdir(self.op_path)\n",
    "#         threading.Thread(target=os.system, args=(f\"cd {self.op_path} && {self.command} > /dev/null\",)).start()\n",
    "#         # _thread.start_new_thread(os.system, (f\"cd {self.op_path} && nohup {self.command}\",))\n",
    "#         os.chdir(work_path)\n",
    "#         # statuses = ['passed', 'failed']\n",
    "#         start_time = time.time()\n",
    "#         last_ping = time.time()\n",
    "#         while True:\n",
    "#             time.sleep(1)\n",
    "#             if (os.path.exists(f\"{self.op_path}/gtest-parallel-logs/passed\")):\n",
    "#                 break\n",
    "#             if (os.path.exists(f\"{self.op_path}/gtest-parallel-logs/failed\")):\n",
    "#                 break\n",
    "#             if time_limited and (time.time() - start_time > op_time):\n",
    "#                 print(f\"{datetime.now().strftime('%Y_%m_%d %H:%M:%S')} Sorry, time for operation {self.op} is over\")\n",
    "#                 os.rename(self.op_path, self.op_stopped_path)\n",
    "#                 os.system('kill -9 $(pgrep -f conformanceTests)')\n",
    "#                 return False\n",
    "#             if time.time() - last_ping > ping_time:\n",
    "#                 print(f\"{datetime.now().strftime('%Y_%m_%d %H:%M:%S')} {self.op} ping\")\n",
    "#                 last_ping = time.time()\n",
    "        \n",
    "#         log_files_folder = f\"{self.op_path}/gtest-parallel-logs/failed\"\n",
    "#         failed_logs_result = f\"{self.op_path}/{self.op}_failed_logs_result.txt\"\n",
    "#         if os.path.exists(log_files_folder):\n",
    "#             with open(failed_logs_result, 'w', encoding='utf-8') as result_file:\n",
    "#                 for log_file_name in os.listdir(log_files_folder):\n",
    "#                     log_file_path = os.path.join(log_files_folder, log_file_name)  # !!! везде так же сделать\n",
    "\n",
    "#                     # print(f\"\\n\\n{log_file_path}\\n\\n\")\n",
    "\n",
    "#                     with open(log_file_path, 'r', encoding='utf-8') as file:\n",
    "#                         data = str(file.read())\n",
    "#                         test_filter = '/'.join(re.findall(r\"Google Test filter = ([^\\n]+)\", data))\n",
    "#                         mem_usage = '/'.join(re.findall(r\"MEM_USAGE=([^\\n]+)\", data))\n",
    "#                         failures = '/'.join(re.findall(r\"[^\\n]+pp:\\s*\\d+[^\\n]+\", data))\n",
    "#                         # print(f\"\\n\\n{test_filter}\")\n",
    "#                         # print(f\"\\n\\n{mem_usage}\")\n",
    "#                         # print(f\"\\n\\n{failures}\")\n",
    "#                         result_file.write(test_filter + ',')\n",
    "#                         result_file.write(mem_usage + ',')\n",
    "#                         result_file.write(failures + ';\\n')\n",
    "#                     # with open(log_path, 'r', encoding='utf-8') as file:\n",
    "#                     #     print(file.read())\n",
    "\n",
    "#         print(f\"cd {self.op_path} && {self.report_command}\")\n",
    "#         threading.Thread(target=os.system, args=(f\"cd {self.op_path} && {self.report_command}\",)).start()\n",
    "#         while (not os.path.exists(f\"{self.op_path}/report.xml\")):\n",
    "#             pass\n",
    "#         print(f\"{datetime.now().strftime('%Y_%m_%d %H:%M:%S')} {self.op} was completed\")\n",
    "#         self.op_completed_path = f\"{self.op_path}_{int(time.time() - process_start_time)}s_completed\"\n",
    "#         os.rename(self.op_path, self.op_completed_path)\n",
    "#         return True\n",
    "\n",
    "\n",
    "\n",
    "def generate_ci_data():\n",
    "    data = {}\n",
    "    with open(ci_report_file, 'r') as file:\n",
    "        soup = BeautifulSoup(str(file.read()), 'html.parser')\n",
    "    tbody = soup.findAll('tbody')[1]\n",
    "    for op_tr in tbody.findAll('tr'):\n",
    "        op = op_tr.findAll('th')[0].text\n",
    "        template_td = op_tr.findAll('td')[report_plugin_position]\n",
    "        data[op] = {result: 'untested' for result in ci_results}\n",
    "        for result in data[op].keys():\n",
    "            if len(template_td.find_all('span')) == 4:\n",
    "                data[op][result] = int(re.findall(fr\"{result[0].upper()}:(\\d+)\", template_td.text)[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# def get_from_TensorIterator_report(op: str):\n",
    "#     result = 'TensorIterator not tested'\n",
    "#     folders = [folder for folder in os.listdir(results_path) \n",
    "#         if folder.split('_')[0] == 'TensorIterator' and folder.split('_')[-1] == 'completed']\n",
    "#     if folders:\n",
    "#         report_path = f\"{results_path}/{sorted(folders)[-1]}/report.xml\"\n",
    "#         with open(report_path, 'r', encoding='utf-8') as file:\n",
    "#             re_str = rf'<{op}-\\d+ passed=\"\\d+\" failed=\"\\d+\" skipped=\"\\d+\" crashed=\"\\d+\" passrate=\"\\d+\\.\\d+\" />'\n",
    "#             result = ''.join(re.findall(re_str, file.read()))    \n",
    "#     return result\n",
    "\n",
    "def not_all_ops():\n",
    "    # TODO: Delete operations that have 100% passrate in both lists, a better algorithm\n",
    "    bad_ops = []\n",
    "    for op in ops:\n",
    "        flag = False\n",
    "        if op in run_data:\n",
    "            for result in run_results:\n",
    "                if result not in ['passed']:\n",
    "                    if run_data[op][result] != 'untested' and int(run_data[op][result]) > 0:\n",
    "                        flag = True\n",
    "                        break\n",
    "        if op in ci_data:\n",
    "            for result in ci_results:\n",
    "                if result not in ['passed']:\n",
    "                    if ci_data[op][result] != 'untested' and int(ci_data[op][result]) > 0:\n",
    "                        flag = True\n",
    "                        break\n",
    "        if flag:\n",
    "            bad_ops.append(op)\n",
    "    ops = bad_ops\n",
    "    \n",
    "# [Black] [Blue] [Cyan] [Green] [Magenta] [Red] [White] [Yellow]\n",
    "def get_op_results(run_data, ci_data, op):\n",
    "    color, text, group = None, '', ''\n",
    "    if op in run_data and op in ci_data:\n",
    "        valid_data = True\n",
    "        for run_result in run_results:\n",
    "            if not isinstance(run_data[op][run_result], int):\n",
    "                valid_data = False\n",
    "                break\n",
    "        for ci_result in ci_results:\n",
    "            if not isinstance(ci_data[op][ci_result], int):\n",
    "                valid_data = False\n",
    "                break\n",
    "        if valid_data:\n",
    "            run_sum = 0\n",
    "            for run_result in run_results:\n",
    "                run_sum += run_data[op][run_result]\n",
    "            run_passed = run_data[op]['passed']\n",
    "            ci_sum = 0\n",
    "            for ci_result in ci_results:\n",
    "                ci_sum += ci_data[op][ci_result]\n",
    "            ci_passed = ci_data[op]['passed']\n",
    "            if run_sum == ci_sum and run_passed == ci_passed and run_sum == run_passed:\n",
    "                color, text, group = '#D2E4D6', 'All tests passed', 'None'\n",
    "    else:\n",
    "        if op in ci_data:\n",
    "            ci_untested = True\n",
    "            for ci_result in ci_results:\n",
    "                if ci_data[op][ci_result] != 'untested':\n",
    "                    ci_untested = False\n",
    "                    break\n",
    "            if op not in run_data and ci_untested:\n",
    "                color, text, group = '#D6C1F9', 'No tests', 'None'\n",
    "            \n",
    "    return color, text, group\n",
    "        \n",
    "    \n",
    "\n",
    "def generate_xlsx():\n",
    "    columns = ['Operation', 'Opset', 'ManualInfo', 'AutoInfo', 'Group'] + \\\n",
    "                [f\"RUN {result}\" for result in run_results] + \\\n",
    "                [f\"CI {result}\" for result in ci_results] + ['RUN logs']\n",
    "    columns_len = [len(column) for column in columns]\n",
    "    run_data = generate_run_data()\n",
    "    ci_data = generate_ci_data()\n",
    "    ops = sorted(list(set(list(run_data.keys()) + list(ci_data.keys()))))\n",
    "    for op in ops:\n",
    "        if op in ci_data and op not in run_data and op.split('_')[0] in time_wasting_ops:\n",
    "            print(op)\n",
    "            run_data[op] = {result: 'TIME OUT' for result in run_results}\n",
    "            \n",
    "\n",
    "    # not_all_ops()\n",
    "\n",
    "    workbook_path = f\"{results_path}/table_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.xlsx\"\n",
    "    workbook = xlsxwriter.Workbook(workbook_path)\n",
    "    worksheet = workbook.add_worksheet('report')\n",
    "    for i, column in enumerate(columns):\n",
    "        worksheet.write(0, i, column, workbook.add_format({\"bold\": True}))\n",
    "    for i, op in enumerate(ops):\n",
    "        op_color, op_info, op_group = get_op_results(run_data, ci_data, op)\n",
    "        # print(op, op_color, op_info, op_group)\n",
    "        cell_format = workbook.add_format({'bg_color': op_color}) if op_color else None\n",
    "        shift = 0\n",
    "        worksheet.write(i + 1, shift, op)\n",
    "        columns_len[shift] = max(columns_len[shift], len(str(op)))\n",
    "        shift += 1\n",
    "        worksheet.write(i + 1, shift, int(op.split('-')[-1]))\n",
    "#         shift += 1\n",
    "#         data = get_from_TensorIterator_report(op)\n",
    "#         if data is not None:\n",
    "#             worksheet.write(i + 1, shift, data)\n",
    "        shift += 2\n",
    "        worksheet.write(i + 1, shift, op_info)\n",
    "        shift += 1\n",
    "        worksheet.write(i + 1, shift, op_group)\n",
    "        shift += 1\n",
    "        if op in run_data:\n",
    "            for j, result in enumerate(run_results):\n",
    "                worksheet.write(i + 1, j + shift, run_data[op][result], cell_format)\n",
    "        else:\n",
    "            for j, result in enumerate(run_results):\n",
    "                worksheet.write(i + 1, j + shift, 'untested', cell_format)\n",
    "        shift += len(run_results)\n",
    "        if op in ci_data:\n",
    "            for j, result in enumerate(ci_results):\n",
    "                worksheet.write(i + 1, j + shift, ci_data[op][result], cell_format)\n",
    "        shift += len(ci_results)\n",
    "        if op in logs_files:\n",
    "            with open(logs_files[op], 'r', encoding='utf-8') as file:\n",
    "                worksheet.write(i + 1, shift, ''.join(file.readlines()), cell_format)\n",
    "\n",
    "\n",
    "    for i, column_len in enumerate(columns_len):\n",
    "        if column_len > 0:\n",
    "            worksheet.set_column(i, i, column_len)\n",
    "    workbook.close()\n",
    "\n",
    "def generate_full_report():\n",
    "    if not os.path.exists(results_path):\n",
    "        return\n",
    "    folders = [folder for folder in os.listdir(results_path) if folder.split('_')[-1] == 'completed']\n",
    "    folders = sorted(folders)\n",
    "    ops = [folder.split('_')[0] for folder in folders]\n",
    "    unique_folders, unique_ops = [], []\n",
    "    for i, folder in enumerate(folders):\n",
    "        if ops[i] not in ops[i+1:]:\n",
    "            unique_folders.append(folder)\n",
    "            unique_ops.append(ops[i])\n",
    "    reports_path = f\"{results_path}/reports\"\n",
    "    if os.path.exists(reports_path):\n",
    "        shutil.rmtree(reports_path)\n",
    "    os.makedirs(reports_path)\n",
    "    for i, folder in enumerate(unique_folders):\n",
    "        shutil.copy(f\"{results_path}/{folder}/report.xml\", f\"{reports_path}/report_{unique_ops[i]}.xml\")\n",
    "    full_report_name = f\"full_report_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}_{len(unique_ops)}pcs.xml\"\n",
    "    gen_report_command = f\"{python_exec} {work_path}/merge_xmls.py -i {reports_path} -o {results_path}\"\n",
    "    os.system(gen_report_command)\n",
    "    os.rename(f\"{results_path}/report.xml\", f\"{results_path}/{full_report_name}\")\n",
    "    shutil.rmtree(reports_path)\n",
    "    return f\"{results_path}/{full_report_name}\"\n",
    "    \n",
    "# TODO: get report_file by last name in work path\n",
    "def generate_run_data(logs=False, ops=all_ops):\n",
    "    data = {}\n",
    "    for i, op in enumerate(sorted(ops)):\n",
    "        run_folders = [folder for folder in os.listdir(results_path) \n",
    "                    if re.findall(fr\"^{op}_.+_completed$\", folder)]\n",
    "#         data[op] = {result: 'untested' for result in run_results}\n",
    "        if run_folders:\n",
    "            run_path = f\"{results_path}/{sorted(run_folders)[-1]}\"\n",
    "            for ir_run_folder in os.listdir(run_path):\n",
    "                op_opset = re.findall(fr\"{op}_opset\\d+\", ir_run_folder)[0]\n",
    "                if op_opset not in data:\n",
    "                    data[op_opset] = {result: 0 for result in run_results}\n",
    "                report_path = f\"{run_path}/{ir_run_folder}/report.xml\"\n",
    "                # print(report_path)\n",
    "                if os.path.exists(report_path):\n",
    "                    with open(report_path, 'r') as report_file:\n",
    "                        xml_data = str(report_file.read())\n",
    "                    passed_pattern = fr'<{op}-\\d+ implemented=\".+\" passed=\"1\" failed=\"0\" skipped=\"0\" crashed=\"0\"'\n",
    "                    failed_pattern = fr'<{op}-\\d+ implemented=\".+\" passed=\"0\" failed=\"1\" skipped=\"0\" crashed=\"0\"'\n",
    "                    skipped_pattern = fr'<{op}-\\d+ implemented=\".+\" passed=\"0\" failed=\"0\" skipped=\"1\" crashed=\"0\"'\n",
    "                    crashed_pattern = fr'<{op}-\\d+ implemented=\".+\" passed=\"0\" failed=\"0\" skipped=\"0\" crashed=\"1\"'\n",
    "                    if re.findall(passed_pattern, xml_data):\n",
    "                        data[op_opset]['passed'] += 1\n",
    "                    elif re.findall(failed_pattern, xml_data):\n",
    "                        data[op_opset]['failed'] += 1\n",
    "                        print(ir_run_folder, 'failed') if logs else None\n",
    "                    elif re.findall(skipped_pattern, xml_data):\n",
    "                        data[op_opset]['skipped'] += 1\n",
    "                        print(ir_run_folder, 'skipped') if logs else None\n",
    "                    elif re.findall(crashed_pattern, xml_data):\n",
    "                        data[op_opset]['crashed'] += 1\n",
    "                        print(ir_run_folder, 'crashed') if logs else None\n",
    "                    else:\n",
    "                        data[op_opset]['empty'] += 1\n",
    "                        print(ir_run_folder, 'empty') if logs else None\n",
    "                else:\n",
    "                    data[op_opset]['empty'] += 1\n",
    "                    print(ir_run_folder, 'empty') if logs else None\n",
    "    result_data = {}\n",
    "    for op, results in data.items():\n",
    "        result_data[op.replace('_opset', '-')] = results\n",
    "                    #print(f\"REPORT??? {report_path}\") # change\n",
    "#             data[op] = {}\n",
    "#             for result in run_results:\n",
    "#                 result_path = f\"{run_path}/gtest-parallel-logs/{result}\"\n",
    "#                 data[op][result] = len(os.listdir(result_path)) if path.exists(result_path) else 0\n",
    "\n",
    "#             failed_report = f\"{run_path}/{op}_failed_logs_result.txt\"\n",
    "#             if path.exists(failed_report):\n",
    "#                 logs_files[op] = failed_report\n",
    "    return result_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ops = [op for op in all_ops if op not in skipped_ops + completed_ops + time_wasting_ops]\n",
    "#     ops = time_wasting_ops\n",
    "#     ops = ['Add', 'Abs']\n",
    "#     ops = []\n",
    "    \n",
    "    print(f\"Ops for run: {ops}\")\n",
    "    \n",
    "    for op in ops:\n",
    "        GTestParallel(op).run(4 * 60)\n",
    "#         GTestParallel(op).run(90 * 60)\n",
    "\n",
    "    \n",
    "#     run_data = generate_run_data(True)\n",
    "#     run_data = generate_run_data(True, ['DetectionOutput'])\n",
    "#     run_data = generate_run_data()\n",
    "#     ci_data = generate_ci_data()\n",
    "    \n",
    "#     print(run_data)\n",
    "#     print(ci_data)\n",
    "\n",
    "    generate_xlsx()\n",
    "    \n",
    "#     for op, d in data.items():\n",
    "#         if type(d['passed']) == int and d['passed'] > 0:\n",
    "#             print(op)\n",
    "#     print(data)\n",
    "    \n",
    "#     generate_full_report()\n",
    "#     generate_xlsx()\n",
    "    \n",
    "#         generate_xlsx()\n",
    "#     generate_xlsx()\n",
    "        \n",
    "#     for op in run_data:\n",
    "#         if op not in ci_data:\n",
    "#             print(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in all_ops:\n",
    "    run_folders = [folder for folder in os.listdir(results_path) \n",
    "                   if re.findall(fr\"{op}_.+_completed\", folder)]\n",
    "    if run_folders:\n",
    "        run_folder = sorted(run_folders)[-1]\n",
    "        good_tests, all_tests = re.findall(fr\"{op}_.+_(\\d+)_of_(\\d+)_\\d+s_completed\", run_folder)[0]\n",
    "        if good_tests != all_tests:\n",
    "            print(\"TIME OUT: \", run_folder)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6df6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_precision_irs_dict('Add'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"$(pgrep -f conformanceTests)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff922f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 4\n",
    "data = {}\n",
    "with open(report_file, 'r') as file:\n",
    "    soup = BeautifulSoup(str(file.read()), 'html.parser')\n",
    "tbody = soup.findAll('tbody')[1]\n",
    "for op_tr in tbody.findAll('tr'):\n",
    "    op = op_tr.findAll('th')[0].text.split('-')[0]\n",
    "    template_td = op_tr.findAll('td')[number]\n",
    "    print(op)\n",
    "    data[op] = {result: 'untested' for result in ci_results}\n",
    "    for result in data[op].keys():\n",
    "        print(result)\n",
    "        if len(template_td.find_all('span')) == 4:\n",
    "            data[op][result] = int(re.findall(fr\"{result[0].upper()}:(\\d+)\", template_td.text)[0])\n",
    "print(data)\n",
    "# return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b66ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
